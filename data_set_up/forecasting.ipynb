{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector as msc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import warnings"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "db_host = 'localhost'\n",
    "db_user = 'sec_user'\n",
    "db_pass = 'Password'\n",
    "db_name = 'securities_master'\n",
    "con = msc.connect(host=db_host, user=db_user, password=db_pass, db=db_name)"
   ],
   "id": "5d5911c8996bc125"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def obtain_lagged_series(symbol, start_date, end_date, lags = 5):\n",
    "    \"\"\"\n",
    "    This creates a Pandas DataFrame that stores the percentage returns of the adjusted closing value of\n",
    "    a stock obtained from Yahoo Finance, along with a number of lagged returns from the prior trading days\n",
    "    (lags defaults to 5 days). Trading volume, as well as the Direction from the previous day, are also included\n",
    "    \"\"\"\n",
    "    symbol_select_str = \"\"\"SELECT securities_master.symbol.id\n",
    "                    FROM securities_master.symbol\n",
    "                    where securities_master.symbol.ticker = '%s' \"\"\" % symbol\n",
    "    df = pd.read_sql_query(symbol_select_str, con)\n",
    "    symbol_id = df.iloc[0, 0]\n",
    "    f_start_date = start_date.strftime('%Y-%m-%d')\n",
    "    f_end_date = end_date.strftime('%Y-%m-%d')\n",
    "    price_select_str = \"\"\"SELECT distinct securities_master.daily_price.close_price,\n",
    "                          securities_master.daily_price.volume\n",
    "                          FROM securities_master.daily_price\n",
    "                          where securities_master.daily_price.symbol_id = '%d' and\n",
    "                          securities_master.daily_price.price_date >= '%s' and \n",
    "                          securities_master.daily_price.price_date <= '%s'\n",
    "                          \"\"\" % (symbol_id, f_start_date, f_end_date)\n",
    "    df = pd.read_sql_query(price_select_str, con)\n",
    "    # Create the new lagged DataFrame\n",
    "    df_lag = pd.DataFrame(index=df.index)\n",
    "    df_lag['today'] = df['close_price']\n",
    "    df_lag['volume'] = df['volume']\n",
    "    # Create the shifted lag series of prior trading period close values\n",
    "    for i in range(lags):\n",
    "        df_lag['lag%s' % str(i+1)] = df_lag['today'].shift(i+1)\n",
    "    # Create the returns DataFrame\n",
    "    df_returns = pd.DataFrame(index=df_lag.index)\n",
    "    df_returns['volume'] = df_lag['volume']\n",
    "    df_returns['percent_change'] = df_lag['today'].pct_change()*100\n",
    "    df_returns['percent_change'] = df_returns['percent_change'].fillna(0)\n",
    "    # If any of the values of percentage returns equal zero, set them to\n",
    "    # a small number (stops issues with QDA model in Scikit-Learn)\n",
    "    for i, x in enumerate(df_returns[\"percent_change\"]):\n",
    "        if abs(x) < 0.0001:\n",
    "            df_returns['percent_change'][i] = 0.0001\n",
    "    # Create the lagged percentage returns columns\n",
    "    for i in range(lags):\n",
    "        df_returns[\"lag%s\" % str(i + 1)] = df_lag[\"lag%s\" % str(i + 1)].pct_change() * 100.0\n",
    "    # Create the \"Direction\" column (+1 or -1) indicating an up/down day\n",
    "    df_returns[\"direction\"] = np.sign(df_returns[\"percent_change\"])\n",
    "    return df_returns.fillna(0)"
   ],
   "id": "8f24c7edb2cf7d19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\n",
    "    # create a lagged series of returns for any stock on the S&P\n",
    "    stock_returns = obtain_lagged_series('LLY', datetime(2019,1,1),\n",
    "                                         datetime(2024, 8, 20), 2)\n",
    "    # print(stock_returns)\n",
    "    X = stock_returns[[\"lag1\", \"lag2\"]]\n",
    "    y = stock_returns[\"direction\"]\n",
    "    # split the data into training data and validation data\n",
    "    train_x = X.iloc[:750]\n",
    "    train_y = y.iloc[:750]\n",
    "    val_x = X.iloc[750:]\n",
    "    val_y = y.iloc[750:]\n",
    "    # Create the (parametrised) models you will be using\n",
    "    models = [(\"LR\", LogisticRegression()),\n",
    "              (\"LDA\", LDA()),\n",
    "              (\"QDA\", QDA()),\n",
    "              (\"LSVC\", LinearSVC()),\n",
    "              (\"RSVM\", SVC(\n",
    "                  C=1000000.0, cache_size=200, class_weight=None,\n",
    "                  coef0=0.0, degree=3, gamma=0.0001, kernel='rbf',\n",
    "               max_iter=-1, probability=False, random_state=None,\n",
    "               shrinking=True, tol=0.001, verbose=False)),\n",
    "              (\"RF\", RandomForestRegressor(\n",
    "                n_estimators=1000, criterion='absolute_error',\n",
    "                max_depth=None, min_samples_split=2,\n",
    "                min_samples_leaf=1, max_features= 5000,\n",
    "                bootstrap=True, oob_score=False, n_jobs=1,\n",
    "                random_state=None, verbose=0))]\n",
    "    # Iterate through the models\n",
    "    for model in models:\n",
    "        model[1].fit(train_x, train_y)\n",
    "        # Make an array of predictions on the value set\n",
    "        predictions = model[1].predict(val_x)\n",
    "        # Output the hit-rate and confusion matrix for each model\n",
    "        print('using %s your hit_rate is %s' % (model[0], model[1].score(val_x, val_y)))\n",
    "        print('using %s your confusion matrix is %s' % (model[0], confusion_matrix(val_y, predictions)))"
   ],
   "id": "10385e2baba08619"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
